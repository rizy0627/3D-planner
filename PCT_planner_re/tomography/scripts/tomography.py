#!/usr/bin/python3
import argparse
import os
import sys
import time
import pickle
from typing import Optional
import numpy as np
import open3d as o3d
from typing import Optional

import rclpy
from rclpy.node import Node
from rclpy.clock import Clock
from rclpy.time import Time
from rclpy.qos import QoSProfile, QoSHistoryPolicy, QoSReliabilityPolicy, QoSDurabilityPolicy

from std_msgs.msg import Header
from sensor_msgs.msg import PointCloud2
import sensor_msgs_py.point_cloud2 as pc2


from tomogram import Tomogram

sys.path.append('../')
from config import POINT_FIELDS_XYZI, GRID_POINTS_XYZI
from config import Config
from config import scene

rsg_root = os.path.dirname(os.path.abspath(__file__)) + '/../..'


class Tomography(Node):
    def __init__(self, cfg: Config, scene_cfg: scene.Scene):
        super().__init__('pointcloud_tomography')

        self.cfg = cfg

        self.qos = QoSProfile(
            depth=1,
            reliability=QoSReliabilityPolicy.RELIABLE,
            durability=QoSDurabilityPolicy.TRANSIENT_LOCAL
        )

        self.export_dir = rsg_root + cfg.map.export_dir
        self.pcd_file = scene_cfg.pcd.file_name
        self.resolution = scene_cfg.map.resolution
        self.ground_h = scene_cfg.map.ground_h
        self.slice_dh = scene_cfg.map.slice_dh

        self.center = np.zeros(2, dtype=np.float32)
        self.tomogram = Tomogram(scene_cfg)

        print(scene_cfg.pcd.file_name)
        if self.pcd_file is None:
            raise ValueError("PCD file name is not specified.")
        else:
            points = self.loadPCD()


        # Process
        self.process(points)

    def initROS(self):
        self.map_frame = self.cfg.ros.map_frame
        pointcloud_topic = self.cfg.ros.pointcloud_topic
        layer_G_topic = self.cfg.ros.layer_G_topic
        layer_C_topic = self.cfg.ros.layer_C_topic


        self.pointcloud_pub = self.create_publisher(PointCloud2, pointcloud_topic, self.qos)

        self.layer_G_pub_list = []
        self.layer_C_pub_list = []

        for i in range(self.n_slice):
            layer_G_pub = self.create_publisher(PointCloud2, layer_G_topic + str(i), self.qos)
            self.layer_G_pub_list.append(layer_G_pub)
            layer_C_pub = self.create_publisher(PointCloud2, layer_C_topic + str(i), self.qos)
            self.layer_C_pub_list.append(layer_C_pub)

        tomogram_topic = cfg.ros.tomogram_topic
        self.tomogram_pub = self.create_publisher(PointCloud2, tomogram_topic, self.qos)


    def loadPCD(self):
        pcd = o3d.io.read_point_cloud(f"{rsg_root}/rsc/pcd/{self.pcd_file}")
        points = np.asarray(pcd.points).astype(np.float32)

        self.get_logger().info(f"PCD points: {points.shape[0]}")

        if points.shape[1] > 3:
            points = points[:, :3]
        
        self.points_max = np.max(points, axis=0)
        self.points_min = np.min(points, axis=0)           
        self.points_min[-1] = self.ground_h
        self.map_dim_x = int(np.ceil((self.points_max[0] - self.points_min[0]) / self.resolution)) + 4
        self.map_dim_y = int(np.ceil((self.points_max[1] - self.points_min[1]) / self.resolution)) + 4
        n_slice_init = int(np.ceil((self.points_max[2] - self.points_min[2]) / self.slice_dh))
        self.center = (self.points_max[:2] + self.points_min[:2]) / 2
        self.slice_h0 = self.points_min[-1] + self.slice_dh
        self.tomogram.initMappingEnv(self.center, self.map_dim_x, self.map_dim_y, n_slice_init, self.slice_h0)

        self.get_logger().info(f"Map center: [{self.center[0]:.2f}, {self.center[1]:.2f}]", )
        self.get_logger().info(f"Dim_x: {self.map_dim_x}")
        self.get_logger().info(f"Dim_y: {self.map_dim_y}")
        self.get_logger().info(f"Num slices init: {n_slice_init}")

        self.VISPROTO_I, self.VISPROTO_P = \
            GRID_POINTS_XYZI(self.resolution, self.map_dim_x, self.map_dim_y)

        return points
        
    def process(self, points):
        assert self.pcd_file is not None
        map_file = os.path.splitext(self.pcd_file)[0]
        file_path = self.export_dir + map_file + '.pickle'
        
        loaded = False
        
        if os.path.exists(file_path):
            self.get_logger().info(f"Found existing tomogram file: {file_path}")
            try:
                with open(file_path, 'rb') as handle:
                    data_dict = pickle.load(handle)
                    
                # Check parameters
                cache_res = data_dict['resolution']
                cache_center = data_dict['center']
                cache_h0 = data_dict['slice_h0']
                cache_dh = data_dict['slice_dh']
                
                if (np.isclose(cache_res, self.resolution) and
                    np.allclose(cache_center, self.center, atol=1e-3) and
                    np.isclose(cache_h0, self.slice_h0, atol=1e-3) and
                    np.isclose(cache_dh, self.slice_dh, atol=1e-3)):
                    
                    self.get_logger().info("Parameters match. Loading cached tomogram...")
                    tomogram = data_dict['data'].astype(np.float32)
                    
                    layers_t = tomogram[0]
                    trav_grad_x = tomogram[1]
                    trav_grad_y = tomogram[2]
                    layers_g = tomogram[3]
                    layers_c = tomogram[4]
                    loaded = True
                else:
                    self.get_logger().warn("Parameters mismatch. Reprocessing...")
                    self.get_logger().info(f"Cache: res={cache_res}, center={cache_center}, h0={cache_h0}, dh={cache_dh}")
                    self.get_logger().info(f"Current: res={self.resolution}, center={self.center}, h0={self.slice_h0}, dh={self.slice_dh}")
                    
            except Exception as e:
                self.get_logger().warn(f"Error loading cache: {e}. Reprocessing...")

        if not loaded:
            t_map = 0.0
            t_trav = 0.0
            t_simp = 0.0
            t_all = 0.0
            n_repeat = 10

            """ 
            GPU time benchmark, where CUDA events are synchronized for correct time measurement.
            The function is repeatedly run for n_repeat times to calculate the average processing time of each modules.
            The time of the first warm-up run is excluded to reduce timing fluctuation and exclude the overhead in initial invocations.
            See https://docs.cupy.dev/en/stable/user_guide/performance.html for more details
            """
            for i in range(n_repeat + 1):
                t_start = time.time()
                layers_t, trav_grad_x, trav_grad_y, layers_g, layers_c, t_gpu = self.tomogram.point2map(points)

                if i > 0:
                    t_map += t_gpu['t_map']
                    t_trav += t_gpu['t_trav']
                    t_simp += t_gpu['t_simp']
                    t_all += (time.time() - t_start) * 1e3

            self.get_logger().info(f"Num slices simp: {layers_g.shape[0]}")
            self.get_logger().info(f"Num repeats (for benchmarking only): {n_repeat}")
            self.get_logger().info(f" -- avg t_map  (ms): {t_map / n_repeat}")
            self.get_logger().info(f" -- avg t_trav (ms): {t_trav / n_repeat}")
            self.get_logger().info(f" -- avg t_simp (ms): {t_simp / n_repeat}")
            self.get_logger().info(f" -- avg t_all  (ms): {t_all / n_repeat}")
            
            self.exportTomogram(np.stack((layers_t, trav_grad_x, trav_grad_y, layers_g, layers_c)), map_file)

        self.n_slice = layers_g.shape[0]

        self.initROS()
        
        # Publish map and layers periodically
        self.points = points
        self.layers_g = layers_g
        self.layers_t = layers_t
        self.layers_c = layers_c
        
        # Publish once immediately
        self.publish_all()
        
        # Create timer for periodic publishing (e.g., every 2 seconds)
        self.timer = self.create_timer(2.0, self.publish_all)

    def publish_all(self):
        self.publishPoints(self.points)
        self.publishLayers(self.layer_G_pub_list, self.layers_g, self.layers_t)
        self.publishLayers(self.layer_C_pub_list, self.layers_c, None)
        self.publishTomogram(self.layers_g, self.layers_t)

    def exportTomogram(self, tomogram, map_file):        
        data_dict = {
            'data': tomogram.astype(np.float16),
            'resolution': self.resolution,
            'center': self.center,
            'slice_h0': self.slice_h0,
            'slice_dh': self.slice_dh,
        }
        file_name = map_file + '.pickle'
        with open(self.export_dir + file_name, 'wb') as handle:
            pickle.dump(data_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)

        self.get_logger().info(f"Tomogram exported: {file_name}")

    def publishPoints(self, points):
        header = Header()
        header.stamp = self.get_clock().now().to_msg()

        header.frame_id = self.map_frame

        point_msg = pc2.create_cloud_xyz32(header, points)
        self.pointcloud_pub.publish(point_msg)

    def publishLayers(self, pub_list, layers, color=None):
        header = Header()
        header.stamp = self.get_clock().now().to_msg()

        header.frame_id = self.map_frame

        layer_points = self.VISPROTO_P.copy()
        layer_points[:, :2] += self.center

        for i in range(layers.shape[0]):
            layer_points[:, 2] = layers[i, self.VISPROTO_I[:, 0], self.VISPROTO_I[:, 1]]
            if color is not None:
                layer_points[:, 3] = color[i, self.VISPROTO_I[:, 0], self.VISPROTO_I[:, 1]]
            else:
                layer_points[:, 3] = 1.0
        
            valid_points = layer_points[~np.isnan(layer_points).any(axis=-1)]
            points_msg = pc2.create_cloud(header, POINT_FIELDS_XYZI, valid_points)
            pub_list[i].publish(points_msg) 

    def publishTomogram(self, layers_g, layers_t):
        header = Header()
        header.stamp = self.get_clock().now().to_msg()
        header.frame_id = self.map_frame

        n_slice = layers_g.shape[0]
        vis_g = layers_g.copy()
        vis_t = layers_t.copy() 
        layer_points = self.VISPROTO_P.copy()
        layer_points[:, :2] += self.center

        global_points: Optional[np.ndarray] = None
        
        for i in range(n_slice - 1):
            mask_h = (vis_g[i + 1] - vis_g[i]) < self.slice_dh
            vis_g[i, mask_h] = np.nan
            vis_t[i + 1, mask_h] = np.minimum(vis_t[i, mask_h], vis_t[i + 1, mask_h])
            layer_points[:, 2] = vis_g[i, self.VISPROTO_I[:, 0], self.VISPROTO_I[:, 1]]
            layer_points[:, 3] = vis_t[i, self.VISPROTO_I[:, 0], self.VISPROTO_I[:, 1]]
            valid_points = layer_points[~np.isnan(layer_points).any(axis=-1)]
            if global_points is None:
                global_points = valid_points
            else:
                global_points = np.concatenate((global_points, valid_points), axis=0)

        layer_points[:, 2] = vis_g[-1, self.VISPROTO_I[:, 0], self.VISPROTO_I[:, 1]]
        layer_points[:, 3] = vis_t[-1, self.VISPROTO_I[:, 0], self.VISPROTO_I[:, 1]]
        valid_points = layer_points[~np.isnan(layer_points).any(axis=-1)]

        assert global_points is not None
        global_points = np.concatenate((global_points, valid_points), axis=0)
        
        points_msg = pc2.create_cloud(header, POINT_FIELDS_XYZI, global_points)
        self.tomogram_pub.publish(points_msg)


if __name__ == '__main__':
    import importlib

    rclpy.init()
    parser = argparse.ArgumentParser()
    parser.add_argument('--scene', type=str, help="Scene name: ['Spiral', 'Building', 'Building2', 'Plaza', 'Map', 'Company']")
    parser.add_argument("--step_max", type=float, default=0.2, help="Maximum step size")
    args = parser.parse_args()

    scene_name: str = args.scene.lower()
    module_name = f"config.scene_{scene_name}"
    class_name = f"Scene{args.scene.capitalize()}"

    scene_module = importlib.import_module(module_name)
    scene_cfg = getattr(scene_module, class_name)()
    scene_cfg.trav.step_max = args.step_max

    cfg = Config()

    node = Tomography(cfg, scene_cfg)

    try:
        rclpy.spin(node)

    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()
